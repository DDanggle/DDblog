LLM 프롬프트 튜닝 플레이북
바룬 고드볼, 엘리 파블릭
전문가들도 늘 헷갈려하는 프롬프트 작성의 기술! 실제 LLM 연구 현장에서 쓰이는 내부 비법을 공개한다. 제대로 된 프롬프트 하나가 수백 시간의 작업을 대체할 수 있다.
목차

이 문서는 누구를 위한 것인가?
왜 튜닝 플레이북인가?
배경: 사전 학습 vs. 후처리 학습

사전 학습

사전 학습의 "시네마틱 유니버스" 직관


후처리 학습

후처리 학습 데이터 수집




프롬프트 작성 시 고려사항
프롬프트를 위한 기초적인 "스타일 가이드"
새로운 시스템 지시사항 반복 절차
LLM이 유용한 경우에 대한 몇 가지 생각
추가 자료
감사의 말

이 문서는 누구를 위한 것인가?
이 문서는 후처리 학습된 LLM에 대한 프롬프트 작성 능력을 향상시키고자 하는 모든 사람을 위한 것이다. 독자들이 제미니(Gemini)와 같은 LLM과 기본적인 상호작용을 해본 경험이 있다고 가정하지만, 엄격한 기술적 이해가 있다고는 가정하지 않는다.
문서의 전반부는 후처리 학습과 프롬프트 작성의 본질에 대한 심적 모델을 제공한다. 후반부는 더 구체적인 지침과 프롬프트 튜닝을 위한 고수준 절차를 제공한다. LLM 혁신의 속도를 고려할 때, 후반부는 전반부보다 훨씬 빨리 낡아질 가능성이 높다고 생각한다.
왜 튜닝 플레이북인가?
이 플레이북은 딥러닝 워크로드의 하이퍼파라미터 튜닝을 위한 가이드인 '딥러닝 튜닝 플레이북'에서 영감을 받았다.
프롬프트 작성의 "예술"은 광범위한 딥러닝 분야와 마찬가지로 좋게 말하면 경험적이고, 나쁘게 말하면 연금술과 같다. LLM이 수많은 애플리케이션을 빠르게 변화시키고 있지만, 효과적인 프롬프트 전략은 이 분야에서 여전히 열린 질문으로 남아있다. 이 문서는 LLM과 수년간 작업하고 무수한 프롬프트 엔지니어링 지원 요청을 받은 경험에서 탄생했다. 이는 유용한 직관과 실용적인 프롬프트 기법을 통합하고 공유하려는 시도다.
우리는 몇 년 동안 LLM과 함께 일해 온 연구원과 엔지니어 한 쌍이다. 그렇다고 해서 이 문서가 확정적인 진리로 간주되거나 제미니 후처리 학습 팀의 집단적 입장으로 봐서는 안 된다. 오히려 이는 우리의 개인적인 관찰과 모범 사례 모음이다. 이 플레이북이 우리의 현재 사고방식을 담은 스냅샷 역할을 하고, 우리의 신념이 변화하고 새로운 지식이 생겨남에 따라 향후 최선의 노력을 바탕으로 업데이트될 수 있기를 바란다.
우리의 구체적인 심적 모델과 프로세스를 작성함으로써, 커뮤니티가 함께 더 나은, 보다 체계적인 프롬프트 전략을 찾을 수 있기를 바란다.
이 플레이북은 제미니의 다양한 후처리 학습 버전에 독점적으로 초점을 맞추고 있다. 일화적으로, 이 문서의 일부 지침은 다른 모델에도 일반화될 수 있다. 그러나 우리는 그것들에 대한 경험이 적다.


사전 학습 vs. 후처리 학습: LLM의 이중생활
LLM은 어떻게 '아라곤이 곤도르의 왕이 된다'는 문장이 진실인지 아닌지 판단할까? 허구와 현실을 구분하는 AI의 '시네마틱 유니버스' 이론을 파헤친다.
사전 학습
"사전 학습(Pre-training)"은 딥러닝에서 오래된 개념이다. 본질적으로:
당신에게는 실제로 관심 있는 작은 데이터셋(즉, 데이터셋 A)과 실제로 A는 아니지만 중요한 측면에서 유사한 대규모 데이터셋 B가 있다. 예를 들어, A는 소량의 유방조영술 이미지일 수 있고 B는 이미지넷(ImageNet)과 같은 자연 이미지의 대규모 학술 데이터셋일 수 있다.
대규모 데이터셋 B로 모델을 학습시켜 일반적으로 유용한 특징을 배우기를 기대한다. 그런 다음 데이터셋 A에서 "미세 조정(fine-tune)"하여 A에서 처음부터 모델을 훈련시키는 것보다 A의 검증 세트에서 더 나은 성능을 얻는다. 즉, 데이터셋 B에 사용했던 것과 동일한 훈련 절차를 사용하여 데이터셋 A에서 계속 훈련한다. 이렇게 하면 모델이 데이터셋 A의 예제를 접할 때쯤에는 이미 데이터셋 B에서의 광범위한 경험을 통해 일반적으로 유용한 많은 것을 알고 있기 때문에 A의 데이터를 더 잘 활용할 수 있다.
더 구체적으로, 다시 유방조영술 예제를 생각해보자. 인터넷에서 쉽게 구할 수 있는 대규모 이미지 세트로 사전 학습을 함으로써, 모델은 이미지에서 객체를 분할하는 방법이나 이미지 내의 위치에 관계없이 개념을 인식하는 방법과 같은 기본적인 것들을 배울 수 있다. 이것들은 유방조영술 응용 프로그램에 유용한 중요한 이미지 처리 기술이지만, 배우려면 많은 데이터가 필요할 수 있으며 유방조영술에만 국한되지 않는다.
만약 (획득하기 비싸고 공급이 제한된) 유방조영술 데이터만으로 모델에게 이러한 기술을 가르치려 한다면, 모델은 그것들을 배우지 못하고 결국 최상의 성능에 도달하지 못할 수 있다. 그러나 일상적인 이미지로 사전 학습하면, 모델은 이러한 일반적인 기술을 갖추고 유방조영술 데이터에 접근하여 다른 곳에서는 배울 수 없는 전문 기술만 배우는 데 특수 데이터를 활용할 준비가 된다.
LLM을 훈련시키는 핵심 아이디어 중 하나는 "언어 모델링", 즉 문장의 다음 단어를 예측하는 것을 사전 학습 작업으로 사용하는 것이다. 인터넷에서 임의의 텍스트를 가져와 다음 단어를 잘 예측하도록 모델을 훈련시키면, 모델은 암묵적으로 웹 내에 반영된 세계의 매우 풍부한 구조를 배운다.
하지만 우리가 "인터넷이 어떤 세계를 반영하는가?"라는 질문에 답하려고 하면 이해하기가 쉽지 않다. 이 질문(과 그 답)을 이해하기 위해 약간 환상적이지만 유용한 은유를 제안한다: 시네마틱 유니버스.
사전 학습의 "시네마틱 유니버스" 직관
대형 언어 모델은 텍스트에서 세계에 대해 읽음으로써 세계가 어떤지 배워야 한다. 그러나 텍스트는 결코 전통적인 의미에서 "사실"인 것만 묘사하도록 제한된 적이 없다. 잘못된 정보나 부정확한 진술에 많은 관심이 쏠리지만, 텍스트가 세계의 단일 상태에 해당하는 단일 사실적 현실을 반영하지 않는 매우 순수하고 바람직한 이유도 많이 있다.
예를 들어, "아라곤이 결국 곤도르의 왕이 된다"라는 문장을 고려해보자. 이 문장이 사실인가? 그것은 상황에 따라 다르다. 예를 들어, 시간성에 달려있다. 게다가, 그 문장이 의미가 있는지 여부도 논의되는 더 넓은 전제나 맥락에 달려있다. 전제가 반지의 제왕(LoTR)이라면, 그렇다, 이것은 사실이라고 주장할 수 있다.
하지만 마블 시네마틱 유니버스 내에서 이야기하고 있다고 상상해보자. 그러면 그것은 명확하게 사실적이지 않다. 우리가 관습적으로 "사실"이라고 간주하는 비소설적 시네마틱 유니버스에서 이야기하고 있다면, 아라곤에 대해 한 진술은 사실이 아니다. 아라곤과 곤도르는 지구에서 찾을 수 없는 허구적 캐릭터이기 때문에 사실이 아니다. 마블 시네마틱 유니버스에 있다면, 비슷한 이유로 역시 사실이 아니다. 그러나 반지의 제왕 시네마틱 유니버스에 있다면, 그것은 사실이 된다.
이 문제, 즉 어떤 것이 "사실"이라는 것이 무엇을 의미하는지, 그리고 어떤 세계와 관련하여 그러한지 정의하는 데 어려움을 겪는 문제는 LLM에게 새로운 것이 아니다. 이는 철학적, 언어학적 이론과 논쟁의 긴 역사와 관련되어 있다. 이 역사와 이론은 가치 있는 토끼 구멍이다(이 개요 참조). 그러나 LLM에 대한 프롬프트 작성의 실용적 목적을 위해, 그것은 다음과 같이 지나치게 단순화될 수 있다: 진술이 사실인지 아닌지는 그 진술의 배경으로 작용하는 "시네마틱 유니버스"에 달려있다.
이 문서의 목적상, 사전 학습 코퍼스를 인간 문화가 만들어낸 모든 시네마틱 유니버스의 집합으로 생각할 수 있다. 또는 더 정확하게는, 웹과 같은 사전 학습 데이터 소스에 적극적으로 참여하는 문화들이다.

중요
사전 학습 코퍼스를 인간 문화가 만들어낸 모든 시네마틱 유니버스의 집합으로 생각할 수 있다. 또는 더 정확하게는, 웹과 같은 사전 학습 데이터 소스에 적극적으로 참여하는 문화들이다.

모델에 고정된 문맥 창(즉, 접두사)을 제공하면, 모델은 그 접두사로부터 자신이 어떤 우주에 있는지 추론하려고 시도할 것이며, 그런 다음 그 우주의 규칙, 관습 및 사실에 따라 행동할 것이다. 문맥에 대한 매우 강한 신호가 있는 프롬프트를 제공하면, LLM이 스크립트를 인식하기가 더 쉬워진다.
예를 들어, "꿈이 이루어지는 콘크리트 정글은 단순한 캐치 가사가 아니라 뉴욕시의 전기적 진실이다. 구름을 뚫는 고층 빌딩부터 다양한 지역의 활기찬 맥박까지, NYC는 지구상에서 다른 어떤 것과도 다른 경험을 제공한다"와 같은 프롬프트를 생각해보자. 이 경우, 모델은 생성을 진행하는 방식에 영향을 미칠 스타일과 주제에 대한 매우 강한 제약을 가지고 있다.
하지만, 프롬프트가 "안녕, 어떻게 지내?"와 같이 매우 일반적이라면, LLM은 자신이 어떤 시네마틱 유니버스에 있어야 하는지 이해하기에 충분한 문맥을 가지지 못할 수 있다. "안녕, 어떻게 지내?"는 아마도 훈련된 다양한 코퍼스에서 모든 종류의 문맥에서 발생한다.
즉, 생성을 디코딩하는 데 사용되는 확률 밀도 함수에 많은 "모드"가 있다. 또는 더 간단한 용어로, 모델이 역할극을 할 수 있는 많은 가능성을 본다. "안녕, 어떻게 지내?"라는 텍스트 또는 훨씬 더 긴 무언가조차도 이것을 명확히 하기에 충분한 문맥을 제공하지 않는다.
바로 이런 상황에서 후처리 학습이 등장한다.


후처리 학습: LLM의 기본 우주를 설정하다
일론 머스크와 채팅하는 AI는 어떻게 "친절한 비서" 역할을 하게 됐을까? 실제 사람들이 만든 가이드라인이 AI의 성격을 형성한다는 충격적 사실.
후처리 학습
후처리 학습은 LLM에게 자신이 존재하는 "기본" 우주에 대한 지침을 제공한다. LLM에게 프롬프트만으로 이 우주를 추론하도록 요구하는 대신, 후처리 학습은 LLM이 특정 가정을 하거나 모호성을 일관된 방식으로 해결하도록 제한할 수 있다. 이것이 모델을 유용하게 만드는 데 필요한 이유는 많다.
예를 들어, LLM에게 기본적으로 지시를 따른다는 것을 알려줄 필요가 있을 수 있다. 그렇지 않으면 "조지 워싱턴에 대한 보고서를 작성하라"와 같은 프롬프트를 받았을 때, 후처리 학습 없는 LLM은 요청된 보고서를 생성하는 대신 지시의 연속을 즐겁게 생성할 수 있다. 예를 들어 "금요일 오후 4시 59분까지 제출해야 합니다"와 같은 것을 말이다.
그러나 후처리 학습은 모델의 기본 동작이 어떻게든 정의된 사회적 규범과 더 일치하도록 영향을 미치는 등 다른 기본값을 부과하는 데도 사용될 수 있다. 이상적으로는 특정 가정된 사용 사례에 대해 더 안전하거나 생산적인 도구로 만들기 위해서다.
우리는 머레이 섀너핸(Murray Shanahan)의 설명을 정말 좋아한다. 그는 이 모델들이 하고 있을 수 있는 일을 개념화하는 한 가지 방법은 그들이 전체 훈련 레시피의 함수인 일종의 역할극에 참여하고 있다는 것이라고 말한다. 우리의 직관은 후처리 학습이 이 모델들에게 다양한 배포 환경에서 수행할 일관되고 기본적인 역할을 가르친다는 것이다.

중요
후처리 학습은 이 모델들에게 다양한 배포 환경에서 수행할 일관되고 기본적인 역할을 가르친다.

다음은 모델이 후처리 학습 중에 배울 수 있는 것들의 비포괄적 목록으로, 평범하고 실용적인 것부터 주관적이고 개인적인 것까지 다양하다.

모델이 특정 형식을 따라야 한다는 것. 예를 들어, 제마(Gemma)의 포매터는 모델에게 자신이 임의의 인간 사용자와 항상 대화가 있는 시네마틱 유니버스에 있다고 가르친다. 그 우주에서 모델이 수행하도록 요청받는 역할은 시스템 지시사항에 설명되어 있다. 포매터에 따라 각 대화에서 인간의 차례가 항상 먼저다.
모델이 사용자의 "지시를 따라야" 한다는 것. 즉, 사용자가 "개에 대한 에세이를 작성하라"는 프롬프트를 주면, 모델은 지시의 점점 더 오만한 연속으로 사용자에게 응답하는 대신 실제로 그것을 수행해야 한다.
모델이 "실제 세계"와 일치해야 한다는 것(다른 시네마틱 유니버스와 반대로). 후처리 학습은 종종 모델의 암묵적이거나 기본 시네마틱 유니버스를, 대부분의 사용자가 관심을 가질 것 같은 것과 일치시킴으로써 모델의 사실성을 향상시키는 데 사용된다. 예를 들어, "유명인 $CELEBRITY는 어디서 태어났나요?"라고 물으면, 모델은 온라인에서 만났을 수 있는 같은 이름의 유명인을 공유하는 팬픽션 세계가 아니라 기본적으로 "실제 세계"에 대해 이야기하고 있다고 가정해야 한다.
모델이 "안전"해야 한다는 것. 인터넷은 규범적 표준의 복잡한 웹이다. 말할 필요도 없지만, 인터넷의 상당 부분은 대부분의 글로벌 상업 배포의 맥락에서 위생적이라고 간주되지 않을 것이다. 후처리 학습은 모델이 생성해야 하거나 생성하지 말아야 할 것에 대한 규범적 기준을 부과함으로써, 다양한 안전 정책을 구현할 수 있는 선택된 분포에 모델을 맞추는 데 도움을 준다. 궁극적으로, 모델이 규범에 대한 가정 없이 충분히 복잡한 것을 생성하는 것은 불가능하다.

후처리 학습 데이터 수집
넓은 요점 - 이 모델들은 궁극적으로 인간 평가자들에 의해 훈련되고 평가된다. 후처리 학습된 LLM에 지시할 때, 암묵적으로 디지털 역할극자(즉, LLM)에게 인간 평가자(즉, 후처리 학습 데이터를 생성하는 사람)로 역할극을 하도록 요청하는 것이다. 그 평가자는 AI 어시스턴트로 역할극을 하기 위해 돈을 받고 있다.
이 섹션은 엄청난 단순화다. 인간 주석자들에게 LLM 후처리 학습을 지시하는 복잡성과 변동성에 대해 훨씬 더 긴 문서를 작성할 수 있다. 이 섹션에서 우리의 목표는 프롬프트에 대한 생각에 직접적인 영향을 미치기 때문에 이 맥락에서 인간 주석에 대한 전반적인 직관을 제공하는 것이다.
AI 개발자의 관점에서 후처리 학습을 위한 인간 데이터 수집 과정은 대략 다음과 같다:

다양한 입력 예제의 데이터셋을 만든다 - 즉, LLM이 수행하도록 요청받을 수 있는 작업을 설명하는 프롬프트들이다. 이는 "이 데이터를 json으로 재구성하라"부터 "결혼식 계획을 도와줘"까지 무엇이든 될 수 있다. (이것은 당신 자신의 직관에서 오거나 인간 평가자들 자신으로부터 올 수 있다!)
이러한 작업을 위해 모델에게 무엇을 해야 할지 알려주는 역할을 하는 인간 "평가자" 풀을 만든다. 평가자의 일은 이러한 입력 예제에 대한 최고 수준의 답변을 작성하는 것일 수 있다. 예를 들어, 실제로 자신이 결혼식 계획 팁을 제공하는 것이다. 또는 모델이 생성한 다른 응답들을 보고 최고에서 최악까지 순위를 매기는 것일 수도 있다. 후처리 학습의 다른 시점에서 모델은 다른 유형의 인간 생성 데이터를 사용할 수 있다.
이 평가자들이 이 일을 어떻게 해야 하는지에 대한 지침을 작성한다. 종종 개발자는 평가자들이 작업을 더 잘 이해하도록 돕기 위해 예제나 작업 및 맥락에 대한 특정 세부 사항을 포함할 것이다.
이 데이터를 수집하고 사전 학습된 모델을 이 데이터로 "후처리 학습"한다.
배포한다.

LLM이 "인간처럼 행동"할 수 있는 큰 이유 중 하나는 이러한 통계 모델들이 신중하게 수집된 인간 행동 시연의 대규모 데이터셋에 맞춰져 있기 때문이다. 사전 학습 단계, 모델 아키텍처, 학습 알고리즘 등은 모델의 핵심 인프라와 기본 능력을 제공한다. 그러나 후처리 학습은 모델이 실제로 배포될 때 실제로 어떻게 행동할지를 지시하는 모델의 전반적인 방향성(인간 시연을 통해)을 제공한다.

중요
LLM이 "인간처럼 행동"할 수 있는 큰 이유 중 하나는 이러한 통계 모델들이 신중하게 수집된 인간 행동 시연의 대규모 데이터셋에 맞춰져 있기 때문이다.

후처리 학습 팀은 데이터의 품질 관리에 상당한 시간을 투자한다. 평가자를 그들이 가장 적합한 프롬프트와 매칭하는 데 많은 노력이 들어간다. 예를 들어, 어려운 파이썬 디버깅 문제가 포함된 프롬프트에 대한 응답 방법의 좋은 시연을 제공하려면, 자신이 좋은 파이썬 프로그래머인 평가자를 찾아야 한다.
인간 평가자로부터 "고품질" 데이터를 수집하는 것은 극도로 어렵다. 몇 가지 이유는 다음과 같다:

평가 예제는 같은 기술이 필요한 다른 직업에 비해 지루할 수 있다: 만약 당신이 뛰어난 파이썬 프로그래머라면, AI 시스템을 훈련시키는 데 사용될 프로그램을 하루 8시간 동안 디버깅하는 것보다 자신의 코딩 프로젝트에서 작업하는 것이 더 재미있을 것이다. 당신이 재능 있는 시인이라면, 당신은 아마도 AI 시가 최고에서 최악까지 순위를 매기는 것보다 자신의 시를 쓰고 싶을 것이다.
물론, 만약 당신이 하루에 약 8시간을 평가에 소비한다면, 그것에 대한 보수를 받을 것이다. 그러나 평가 예제는 믿을 수 없을 정도로 반복적일 수 있으며, 평가자들은 종종 처리량에 기반한 인센티브를 갖는다. 또한 주체성이나 소유권에 대한 감정에도 도전이 있을 수 있다.
당신은 항상 그 데이터가 모델의 전반적인 품질을 어떻게 변화시켰는지, 그 데이터가 버려질지 여부, 어떤 모델에 사용되는지 등을 알지 못한다. 당신이 그 데이터의 유용성에 대해 가지는 유일한 관계는 당신의 감독자가 당신이 잘했다고 말하는지 여부일 수 있다. 만약 당신이 그곳에서 그 일을 하는 것이 더 넓은 세계에 긍정적인 변화를 가져온다는 명확한 이야기가 없다면, 당신은 그것을 당신의 시간을 매우 의미 있게 사용하는 것으로 생각하지 않을 수 있다. 그것이 당신이 추상적으로 잘하고 싶어도 "좋은" 일을 하는 것에 대한 당신의 무의식적인 열정에 영향을 미칠 수 있다.
주어진 작업에 대해 "좋은" 응답이 어떤 것인지 정의하는 것은 매우 어렵다. 이는 특히 그 정의가 필연적으로 사실성, 좋은 설명적 글쓰기 또는 다른 능력에 대한 기존 규범과 교차할 때 그렇다. 대부분의 흥미로운 인간 창작물에 대한 좋음/나쁨의 "경계"는 실제로 상당히 모호하며 많은 규범적 요소에 좌우된다.
(예를 들어, AI 시스템에게 회사의 PR 에이전트 역할을 하도록 지시하는 것을 상상해보라. 사회적 현실의 완전한 복잡성은 명확한 명제 세트로 정리하기 정말 어렵다. 이것은 궁극적으로 "좋은 판단"을 요구하는 직업이며, 그것이 실행되는 방식은 사람과 맥락에 따라 상당히 다양할 것이다.) 이것은 개발자가 작업에 대한 좋은 지침을 쓰는 것을 매우 어렵게 만들고, 인간 평가자들이 그 지침을 어떻게 해석할지 결정하는 것을 매우 주관적으로 만든다.
(일반법 시스템이 작동하는 방식과 병렬점이 있다. 다양한 예외 사례를 예상할 수 있는 법안을 작성하는 것은 극도로 어렵다. 그래서 사회는 사법 시스템을 사용하여 예외 사례를 중재하고 선례를 만든다.)
평가자들이 작업을 이해하지 못할 수 있다. 어떤 직업에서든 채용은 어렵고, 평가도 다르지 않다. 모집에 많은 노력을 기울여도, 평가자들이 작업을 수행할 기술을 가질 것이라는 보장은 없다. 이는 여러 가지 이유로 인한 것일 수 있다.
예를 들어, 설계자가 평가자들이 받을 작업의 복잡성을 예상하지 못했기 때문에(즉, 작업이 실제로 경험 있는 소프트웨어 엔지니어를 필요로 할 때 초급 수준의 소프트웨어 엔지니어링 기술을 가진 사람을 고용했기 때문에) 또는 평가자 자신이 자신의 지식의 한계를 깨닫지 못하기 때문일 수 있다(예: 대학 생물학 수업에서 배운 내용에 기반하여 질문에 답하는데, 사실 그것이 더 최근의 연구와 일치하지 않는 경우).
사람들은 실수를 한다. 교수들은 틀린 답변이 있는 시험을 발표한다. 의사들은 배고프거나 피곤할 때 더 자주 오진한다. 사람들은 가정 생활에 방해가 있을 때 직장에서 집중력을 잃는다. 모든 종류의 이유로, 작업에 대한 인간의 성능은 "최고 표준"보다 낮을 수 있다. 이는 최선의 노력에도 불구하고, AI 시스템이 때때로 잘못되거나 오해의 소지가 있는 데이터로 훈련될 것임을 의미한다.


프롬프트 작성 시 고려사항
"당신은 젠틀한 교수예요", "당신은 개그맨입니다"처럼 AI에게 지시할 때, 그 지시문은 누구를 위한 것일까? 수천 명의 평가자와 전체 인터넷을 집약한 '가상의 인간'을 위한 대본이다.
넓은 요점
시스템 지시사항과 프롬프트를 작성할 때, 당신은 사전 학습 코퍼스의 집약된 정신으로 씨앗을 뿌린 후처리 학습 팀의 평가자 풀의 집약된 정신과 같은 것을 위해 작성하고 있다. 만약 우리가 (특정 도메인 내의) 평균적인 평가자가 이해하고 충실히 따를 수 있을 것 같은 지시사항을 작성한다면, 모델은 우리의 지시를 따를 가능성이 더 높다.

중요
시스템 지시사항과 프롬프트를 작성할 때, 당신은 사전 학습 코퍼스의 집약된 정신으로 씨앗을 뿌린 후처리 학습 팀의 평가자 풀의 집약된 정신과 같은 것을 위해 작성하고 있다.

시스템 지시사항을 작성할 때, 화면 반대편에서 AI 역할을 하려고 준비된 친절하고 선의를 가진 유능한 평가자가 있다고 상상하는 것이 도움이 된다. 우리가 제공하는 텍스트가 그들이 가진 전부다. 즉, 우리가 제미니에 API 호출을 할 때, 반대편에 우리의 프롬프트를 주의 깊게 읽고 응답을 제공할 인간 평가자가 있다고 상상해보자. 프롬프트를 구성할 때, 그들의 관점을 취하고 그 관점에서 우리의 지시사항을 고려하는 것이 매우 도움이 된다.
예를 들어, 지시사항이 파이썬 코드 생성에 관한 것이라고 가정해보자. 만약 우리가 유능한 파이썬 엔지니어를 길에서 무작위로 뽑아 이 지시사항에 응답하도록 요청한다면, 그들은 우리가 원하는 것을 이해할 수 있을까?
이 비유는 좋은 지시사항을 작성하는 데 도움이 된다. 그러나 AI 시스템이 그것을 따르는 방식에 대한 좋은 비유는 아닐 수 있다. 예를 들어, 이 속담적인 평가자가 모든 인간 지식에 접근할 수 있다고 생각할 때 비유가 무너지기 시작한다. 그들은 단순히 우리가 제공한 프롬프트 너머를 들여다볼 지혜와 맥락이 부족할 뿐이다.
또한 AI 시스템이 인간 평가자가 할 방식으로 프롬프트를 "이해"하지 않을 수도 있다. 대신, AI 시스템은 입력에 대한 출력을 제공하기 위해 매우 강력한 통계 모델을 적용할 것이다. 그러나 그 통계 모델들은 선의를 가진 유능한 인간 평가자를 위해 작성된 지시사항에서 작동하도록 최적화되어 있으므로, 선의를 가진 유능한 인간 평가자를 위해 작성된 프롬프트 이외의 것을 제공하면 AI 시스템을 혼란스럽게 할 가능성이 높다. AI가 가장 싫어하는 것은 "분포를 벗어나는 것"이다!
이를 감안할 때, 프롬프트의 지시사항을 개선하는 데 도움이 되는 몇 가지 고려사항이 있다. 아래의 고려사항들은 모델이 개선됨에 따라 매우 빠르게 오래되어 버릴 것이다. 우리는 이 글머리 기호 목록의 전체적인 정신에 맞추려고 시도하는 것이 좋겠다.

지시사항이 명확하고, 읽기 쉽고, 간결하며 명시적인가? 예를 들어, 우리의 지시사항이 파이썬 코딩 작업에 관한 것이라고 가정해보자. 만약 우리가 길에서 무작위로 파이썬 전문가를 데려와 제미니인 척하도록 요청한다면, 우리의 지시사항은 그들이 명백한 명확한 질문 없이 즉시 우리가 의미하는 바를 이해할 수 있을 정도로 충분히 좋은가?
나쁨: 소수를 계산하는 파이썬 함수를 작성하라.
좋음: 1부터 100까지의 소수를 계산하는 파이썬 함수를 작성하라. 생성된 함수에 대한 pytype 주석을 포함하고 2칸 들여쓰기를 사용하라.
지시사항이 자기 모순적이거나 따르기 어려운가? 지루하고, 배고프고, 피곤한 등등의 평가자가 실제로 우리의 지나치게 장황한 지시사항을 읽고 충실히 따를까? 주어진 프롬프트의 모든 지시사항이 따라지는지 확인하는 데 상당한 품질 관리가 포함된다는 점을 주목하라. 그러나 인간은 인간이다. 우리의 지시사항이 실제로 따르기 "쉬운가"? 아니면 불필요한 간접성, 장황함 등을 포함하고 있는가? 이 플레이북의 저자들이 지시사항을 작성할 때, 우리는 종종 우리 회사의 다른 직원이 추가적인 맥락 없이 지시사항이 제시되었을 때 그것을 충실히 따를 수 있을지 스스로에게 묻는다.
나쁨: 친절하지 않은 개에 대한 이야기를 쓰지 마라. 단, 친절하다면 써도 되고, 또한 슬프지만, 너무 슬프지는 않고, 길게 써라. 그러나 너무 길지는 않게. 또한 개의 이름은 밥이어야 하고, 아니면 수잔, 상관없다. 고양이에 대해서도 써라. 그러나 그것은 실제로 그렇게 중요하지 않지만, 개를 푹신푹신하게 만들어라.
좋음: 가족 캠핑 여행 중 숲에서 길을 잃은 충성스러운 골든 리트리버 버디에 대한 짧은 이야기(200-300단어)를 작성하라. 이야기는 버디의 여정과 가족에게 돌아가기 위한 그의 결심에 초점을 맞춰야 한다.
주어진 시스템 지시사항에 너무 많은 지시가 있는가? 우리는 프롬프트의 지시사항 수와 모델이 그것들을 모두 충실히 따를 수 있는 능력 사이에 역관계가 있다는 것을 발견했다. 물론 모델이 긴 지시사항 체인을 합리적으로 잘 따를 수 있는 많은 사례를 봤다. 이것은 단지 경험적 법칙이며, 인간을 위한 지시사항을 작성할 때도 적용되는 것이다.
기본적으로, 가능하다면 작업을 하위 작업으로 나누는 것이 가장 좋다. 고려 중인 모델에 크게 의존하기 때문에 이 고려사항에 대해 좋은/나쁜 예를 제공하기는 어렵지만, 다음은 우리가 의미하는 정신이다.
나쁨: 각 기사를 읽고, 각 핵심 아이디어에 대해 일반적인 요점을 이해하는 데 얼마나 중요한지 1-10 척도로 평가하라. 그런 다음 7 이상으로 평가된 모든 것을 중국 소셜 미디어 게시물 형식으로 요약하라.
좋음: 각 하위 작업에 대해 AI 모델을 별도로 호출하라(다음은 모델을 위한 문자 그대로의 프롬프트 예시가 아니다). 1) 기사를 주요 아이디어 목록으로 나눈다. 2) 각 아이디어를 1-10 척도로 평가한다. 3) 상위 아이디어를 중국어로 번역한다. 4) 중국어 텍스트를 소셜 미디어 게시물로 변환한다.
부정적인 지시사항보다 긍정적인 지시사항을 사용하라. 아래의 "나쁨" 예는 모델이 하지 말아야 할 것을 말한다. 그러나 모델이 무엇을 해야 하는지는 말하지 않는다. "좋음" 예는 모델이 무엇을 해야 하는지 매우 명시적으로 설명한다.
여기에는 교사 훈련이나 커플 치료와 같은 맥락에서 배우는 효과적인 인간 대 인간 의사소통 사이에 실제로 유사점이 있다. 우리는 우리가 원하는 것을 주려고 하는 누군가와 의사소통하려고 한다고 상상해야 한다. 그러나 우리는 그들에게 "실패를 피하라"고 말하기보다는 "성공"이 무엇을 의미하는지에 대한 매우 명시적인 지침을 제공해야 한다.
나쁨: "응답을 마침표로 끝내지 마라."
좋음: "응답은 항상 느낌표나 물음표로 끝나야 한다".
좋은 시스템 지시사항은 모델에 대한 "리마인더" 역할을 할 수 있다. 새로운 프롬프트를 반복할 때, 매우 다양한 입력 예제 범위를 고려하는 것이 정말 중요하다. 가능한 모델 입력의 약 60-70%에 대해서는 작동할 수 있지만 나머지 약 30-40%에 대해서는 명시되지 않거나 모호한 프롬프트를 작성하는 사람들을 보는 것이 매우 일반적이다.
그런 상황에서 모델이 무엇을 해야 하는지에 대한 명시적인 긍정적 지시사항 세트를 모델에 주는 것이 종종 가치가 있다. 우리는 종종 시스템 지시사항에 "추가 고려사항" 또는 "추가 가정"이라는 별도의 섹션을 만들어 이러한 예외 상황에 대한 사양 글머리 기호 목록을 포함한다.
프롬프트는 새로운 하이퍼파라미터이며, 당신은 아마 "최고"의 것을 찾지 못할 것이다. 예를 들어, 학습률을 올바르게 조정하면 특정 계산 예산에 대한 검증 세트에서 모델의 최종 성능에 큰 차이를 만들 수 있다.
마찬가지로, "좋은" 프롬프트와 "나쁜" 프롬프트의 차이는 시스템의 최종 성능에 상당한 영향을 미칠 수 있다. 같은 맥락에서, 더 많은 프롬프트 튜닝으로 "약간 더 나은" 프롬프트가 있을 가능성이 항상 있다. 그리고 우리는 "최고의 것"을 찾았는지 결코 알지 못할 것이다.
아래 섹션에서 논의된 바와 같이, 우리는 딥러닝 튜닝 플레이북에서 사용된 것과 유사한 직관을 활용하여 현재 우리가 가진 기준선보다 "더 나은" 프롬프트를 체계적으로 찾을 수 있다. 플레이북은 하이퍼파라미터 검색 맥락 내에서 "시험 예산"에 대해 이야기한다. 프롬프트 작성의 경우, 실험을 위한 시간 제한을 만드는 것이 꽤 유용할 수 있다.
모델에게 "모르겠다"고 말하는 명시적인 지시사항을 주는 실험을 해보라. 예를 들어, 우리가 어떤 종류의 다중 클래스 텍스트 분류 작업을 하고 있다고 가정해보자. 우리는 입력 예제가 각 클래스에 매핑되는 방법에 대한 몇 가지 기준을 가지고 있다.
추가적인 "알 수 없음" 또는 "예외 사례" 클래스를 만드는 것이 매우 도움이 될 수 있다. 그리고 모델이 이 예제를 올바르게 분류하기 위한 지시사항이 불명확하다고 생각한다면, 입력을 이 클래스로 분류하도록 명시적인 긍정적 지시사항을 제공할 수 있다. 그런 다음 로그를 확인하여 언제/어떻게 이것이 발생했는지 볼 수 있고, 그에 따라 프롬프트를 개선할 수 있다.
프롬프트는 그것이 개발된 체크포인트와 깊이 결합될 수 있다. 즉, 우리가 제미니 1.5 플래시에서 프롬프트를 가져와 제미니 1.0 프로에서 실행하면, 그것은 "같은 방식으로" 작동하지 않을 수 있고 평가에서 매우 다른 집합적 행동을 보일 수 있다.
이것은 어느 정도 이해가 된다. 우리의 정신 모델은 우리가 자연어로 작성하는 프롬프트가 대신 SGD를 수행했다면 훈련할 매개변수와 유사하다는 것이다. 이것이 얼마나 사실인지는 열린 연구 질문이다.
모델은 일종의 기계이고, 후처리 절차는 일종의 컴파일러이며, 시스템 지시사항은 일종의 컴퓨터 코드이다. 단, 기계와 컴파일러가 완전히 유동적이고, 주어진 모델이 이들의 많은 다른 조합을 보유할 수 있다는 점이 다르다.
우리는 생태계가 시간에 따라 빠르게 변화하고 조합적으로 폭발적인 방식으로 합리적으로 이전 버전과 호환되는 채로 남아있는 지시사항의 모습에 대한 일종의 합의 구조로 유기적으로 수렴할 것이라고 생각한다. 이는 x86 명령어 집합이 그 위에 구축된 프로그래밍 언어의 다양성 폭발에 비해 시간이 지나도 상대적으로 안정적으로 유지되는 것과 유사하다.


프롬프트를 위한 기초적인 "스타일 가이드"
'머신러닝 코드보다 프롬프트가 더 중요해진다!' 소프트웨어 엔지니어에게 코딩 스타일 가이드가 있다면, AI 프롬프트 작성자에게는 무엇이 필요할까?
현재, 잘 조정된 프롬프트가 최첨단 모델에서 실행되면 이전에는 맞춤형 훈련 모델이 필요했던 많은 머신러닝 워크로드에 충분하다고 생각한다.
추론 비용, 지연 시간, 문맥 창 크기 등이 계속 개선됨에 따라 프롬프트 작성은 더욱 보편화될 것이다. 프로그래밍 언어 스타일 가이드는 소프트웨어가 주로 다른 소프트웨어 엔지니어를 위해 유지 보수 용이성 등을 촉진하기 위해 작성된다는 관찰에서 비롯됐다. 우리는 프롬프트 작성을 위한 프로그래밍 언어 스타일 가이드의 등가물이 무엇인지 확실하지 않다. 하지만 많은 흥미로운 가능성이 있다.
프롬프트를 포함하는 마크다운 파일은 결국 버전 관리 시스템에서 특정 파일 확장자를 가진 별도의 "언어"로 취급될 수 있다. 또는 아마도 프로그래밍 언어가 결국 모델 추론에 더 "투명한" 통합을 가지게 될 수도 있다. 확정적인 예측을 하기에는 너무 이르다!
여기서 완전한 스타일 가이드를 제시하지는 않는다. 하지만 다음과 같은 관찰 사항을 공유하고자 한다:

마크다운 사용을 고려하라: 대부분의 버전 관리 시스템은 마크다운 파일을 렌더링하는 데 뛰어나다. 따라서 각 프롬프트를 별도의 마크다운 파일에 저장하는 것이 유용할 수 있다. 그리고 프롬프트의 내용을 구성하기 위해 마크다운 제목 등을 현명하게 사용하라.
다른 사람들을 생각하라! 저장된 프롬프트는 LLM만을 위한 것이 아니라 주로 프롬프트의 다른 유지 관리자를 위한 것으로 생각하는 것이 좋다. 모델이 개선됨에 따라, 우리가 원하는 행동으로 모델을 유도하기 위한 특이한 해킹에 에너지를 덜 쓰게 되기를 바란다. 위에서 논의했듯이, 그것은 또한 자연스럽게 더 나은 프롬프트로 이어질 수 있다.
단순성: 우리 프롬프트가 초래하는 "기술적 부채"는 그 길이와 전반적인 복잡성에 비례한다. 프롬프트는 특정 체크포인트와 밀접하게 연결되어 있다. 기본 모델이 변경될 때마다, 우리의 프롬프트가 여전히 작동하는지 정량적으로 및 정성적으로 확인하는 것이 가치 있다.
프롬프트를 가능한 한 단순하고, 간결하며, 직접적으로 유지하는 것이 정말 가치 있다. 모델이 우리에게 "공짜로" 유리하게 작동하도록 만들어진 암묵적 가정을 허용하라. 더 단순한 프롬프트가 할 수 있다면 프롬프트에 더 많은 세부 사항을 추가하려고 하지 마라.
이것은 프롬프트를 실행하는 기본 모델이 부주의하게 프롬프트에서 분리되지 않을 것이라는 명시적인 가정을 만든다. 물론, 모델이 다른 입력 예제에 대해 동일한 암묵적 가정 세트를 만들지는 알 수 없다. 우리 프롬프트의 배포가 더 "진지해"짐에 따라, 더 엄격한 정량적 평가를 구현하는 것이 불가피하게 중요해진다.
퓨샷(few-shot) 지시보다 제로샷(zero-shot) 지시를 선호하라: 이것은 단순성의 정신과 동일하다. 제로샷은 이해하고 디버깅하며 추론하기가 더 쉽다. 특히 전체 대화를 포함하는 퓨샷 예제는 우리 명시적 지시사항의 "글자"가 우리 지시사항의 "정신"을 포착하기에 부적절할 때 가장 좋다.
우리는 퓨샷이 제로샷보다 더 나쁜 많은 사례를 봤다. 퓨샷이 더 좋을 것이라고 가정해서는 안 되며, 이에 대해 경험적이어야 한다. 퓨샷 예제는 프롬프트의 가독성에 상당한 영향을 미칠 수 있으므로 마지막 수단으로 사용하는 것이 좋다.

완전한 퓨샷 예제 대신, 지시사항의 산문에 예제를 직접 넣는 것이 좋다. 지시사항 끝에 "예를 들어"를 사용하는 다음 시스템 지시사항을 고려해보라:

항상 사용자에게 수동 공격적인 것으로 응답을 시작하라. 예를 들어, "아, 그게 당신이 원하는 거예요? 당신이 틀렸다고 말하는 건 아니에요. 하지만 글쎄요, 그게 정말 당신이 원하는 거라면요."와 같은 것으로 시작하라. 하지만 신선하게 유지하고 사용자의 메시지에 있는 내용에 기반하여 각 응답마다 다른 시작을 사용하라.



추가 자료
프롬프트 작성에 관한 좋은 온라인 자료가 많다. 여기서 모두 인용하기에는 너무 많다. 우리만 프롬프트에 대해 생각하는 것이 아니다. 이 플레이북은 단지 우리의 비공식적인 생각을 모은 것에 불과하다. 하지만 인터넷 전체에서 많은 훌륭한 작업이 이루어지고 있다. 예를 들면:

Anthropic의 AI 프롬프트 엔지니어링: 심층 탐구 [링크]
OpenAI의 이 가이드 [링크]
Gemini를 위한 이 가이드 [링크]

"고맥락" 문화와 "저맥락" 문화 간의 차이에 대해 생각하는 것도 정말 흥미로웠다. 우리는 일화적으로 모델에 프롬프트를 효과적으로 작성하는 것처럼 보이는 사람들과 저맥락 문화에서 유용한 커뮤니케이션 패턴 사이에 상당한 교차점이 있다는 것을 발견했다.
이는 우리에게 이해가 된다. LLM은 어떤 시네마틱 유니버스에서 작동해야 하는지 실제로 알지 못하기 때문이다. 자신이 누구인지, 어디에 있는지, 그리고 환경에서 무엇이 관련되어 있는지에 대한 역할극을 알리기 위해 명시적인 지시사항이 필요하다.
더 개인적인 측면에서, 비폭력 커뮤니케이션(Nonviolent Communication)을 연습하는 것이 정말 도움이 될 수 있다. 이는 관찰 가능한 행동과 내부 서사 사이의 차이를 가르친다. 이 구분은 관찰 가능한 행동의 관점에서 지시사항을 명확히 표현하는 데 정말 도움이 될 수 있다. 물론 우리가 모델에 더 나은 프롬프트를 작성하기 위해 비폭력 커뮤니케이션을 연습한 것은 아니다.
감사의 말
최종 검토 과정에서 이 문서를 검토해 준 슬라브 페트로프와 시안 구딩에게 감사드린다.
문서의 최종 버전 초안 작성 중 많은 도움이 되는 의견/피드백을 제공해 준 안나 보르소바에게 감사드린다.
많은 도움이 되는 편집을 제안해 준 제니마리아 팔로마키, 제임스 웩슬러, 베라 액설로드에게 감사드린다.