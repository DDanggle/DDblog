
이제 우리는 AI 시대에 살고 있다



Scaling law는 끝났는가? 
 https://www.felicis.com/insight/ai-data-infrastructure



"우리는 새로운 산업혁명의 시작점에 서있다. 이번엔 전기가 아닌 지능을 만들고 있고, [오픈소스]는 모든 기업을 깨웠다. 모든 기업이 AI 기업이 될 수 있는 가능성을 열어준 것"
NVIDIA CEO 젠슨 황


개요

우리는 세상을 변화시키고자 하는 명확한 비전을 가지는 창업자를 좋아합니다. 현재 전 분야에서 스타트업들이 AI 혁명을 이끌어낼 인프라를 구축해나가고 있습니다. 우리는 반도체부터 데이터센터, 클라우드 업체들이 만들어내는 변화를 지켜봤고, 다음의 인프라 투자 영역은 커스텀 AI 애플리케이션 가능하도록 만들어주는 데이터 인프라라고 생각합니다. 


문서더미에서 뽑아내야하는 필요성을 이제 설명할 필요는 없지만, 생성형 AI가 대두되면서 엄청난 데이터들이 필요한 애플리이케이션들이 나왔다.  학습과 추론 모두에 고품질 데이터는 필수적이고, 기업들은 이 데이터를 확보할 방법이 필요하다. 게다가 고려해야할 건 데이터 규모 뿐 아니라, 비디오, 이미지, 오디오도 있고 위성 이미지와 로봇 센서 데이터와 같은 공간 데이터로 확장되고 있다. 


하지만 핵심 질문을 놓치지 맙시다: AI로 인해 이 데이터 계층에서 어떤 새로운 영역이 가장 즉각적으로 빠르게 바뀌게 될까?
우리는 비정형 데이터 추출과 파이프라인, 검색 증강 생성(RAG), 데이터 큐레이션, 데이터 저장소, AI 메모리 등 데이터 환경 전반에 걸친 혁신을 목격하고 있으며, 이 글의 목표는 AI 데이터 인프라 환경을 분석하고, 우리가 보고 있는 트렌드를 공유하며, 가장 유망한 혁신 분야에 대한 생각을 공유해본다. 

먼저, 데이터 인프라 환경에 대한 배경 지식부터 다루어보겠다. 

=======


AI 데이터 인프라 환경

이 그래픽을 만들 때, 우리는 학습과 추론을 위한 데이터 흐름을 포함하여 AI 가치 사슬 전반에 걸친 데이터의 흐름을 (가능한 한 단순하게) 보여주고자 했습니다.
데이터 인프라 가치 사슬을 볼 때, 우리는 다음 여섯 가지 영역을 봅니다:

소스
수집 및 변환
저장
학습
추론
데이터 서비스
이러한 부분들을 다음과 같이 시각화했습니다:

원천데이터 
원천 데이터 유형은 사용 사례에 따라 다양하다. 보통, 기업의 비즈니스 데이터는 주로 Salesforce 같은 비즈니스 애플리케이션에 저장되며, 거래 데이터는 PostgreSQL이나 Oracle 데이터베이스에 저장된다. 또한 실시간 분석을 위한 데이터 수집에는 센서, 제조, 일부 의료 데이터와 같은 다른 성격을 띄는 원천 데이터가 필요하며 "실시간(real-time)" 데이터라고 한다.

특히, AI 애플리케이션에서는 합성 데이터와 웹 데이터의 중요성이 커졌다. 합성 데이터는 실제로 일어난 일 기반으로 수집되는 게 아니라, 인공적으로 생성된 데이터다. 합성 데이터는 데이터 규정 준수를 유지하면서도 실제 데이터를 획득, 정제, 레이블링하는 것보다 훨씬 저렴한 방식으로 수집할 수 있다. 
합성 데이터는 ML 훈련에서 활용도가 높아지고 있었지만, 합성 데이터가 이상치 통계 데이터를 잘 표현하지 못해 모델 성능 최적화에 도움이 되지 않는다는 이야기도 있다. 그렇기 때문에 훈련 데이터세트에서 전적으로 합성 데이터로만 구성되지는 않겠지만, NVIDIA가 최근 발표한 합성 데이터를 생성하는 오픈 모델군인  Nemotron-4 340B로 인해 합성 데이터가 더욱 주류가 되어가는 것을 보고 있다. 


웹 데이터는 모델 훈련이나 미세 조정을 위한 모든 공개 데이터에 대한 접근을 제공한다. 웹 스크래핑은 새로운 개념이 아니지만, 대규모 모델을 훈련시키기에 충분한 품질의 데이터를 모으는 데 필요한 엄청난 양의 스크래핑 볼륨은 새로운 것이다. 이를 이해하기 위해, Epoch AI의 한 연구에 따르면 기술 기업들이 AI 언어 모델을 위한 공개적으로 이용 가능한 훈련 데이터를 2026년에서 2032년 사이에 소진할 것으로 전망하고 있다. 웹스크래핑된 데이터는 대규모 기초 모델의 훈련 데이터 세트에서 핵심적인 역할을 해왔다.

데이터 저장소

전통적으로 분석 데이터는 데이터 웨어하우스에 저장되었지만, 이제 점차 데이터는 데이터 레이크에 저장되고, 오픈 테이블, 카탈로그, 쿼리 엔진의 레이크하우스 아키텍처를 사용해 쿼리된다. AI 워크로드를 위한 비정형 데이터는 보통 벡터 데이터베이스에 임베딩 형태로 저장된다. 

모델 훈련

AI 알고리즘은 지도, 비지도, 강화 학습 세 가지 주된 훈련 방법을 사용한다. 지도 학습에서는 모델에 레이블이 있는 데이터가 주어지고, 그 레이블된 데이터와 일치하도록 결과를 출력하는 법을 학습한다. 비지도 학습에서는 대량의 데이터을 모델에서 인풋으로 받아 독립적으로 관계를 학습한다. 대규모 언어 모델에서 일반적인 "사전 훈련"은 비지도 학습으로 구성되어 모델이 데이터 세트의 패턴을 인식할 수 있도록 먼저 훈련한다. 그 다음, 모델은 성능을 최적화하기 위해 지도 학습을 사용해서 추가로 훈련하게 된다. 커스텀한 ML 모델은 보통 지도 학습을 사용해 훈련된다.
다음으로, 모델은 RLHF(인간 피드백을 통한 강화 학습)라고도 불리는 강화 학습을 거친다. 이름에서 알 수 있듯이, 모델이 출력을 생성하고 출력을 개선하는 방법에 대해 사람으로부터 피드백을 받는다. 이 과정 전반에 걸쳐 모델은 주어진 상황을 얼마나 잘 모델링할지 지속적으로 평가한다. 특히 정확도, 정밀도, 손실 최소화, 과적합, 과소적합 및 모델의 사용 사례에 특화된 다른 통계들을 살펴본다. 마지막엔, 모델은 안전한 사용자 출력을 생성하고 보안이나 규정 준수 문제가 없도록 보장하기 위해 보안 테스트, 거버넌스, 감사를 포함한 다양한 최종 단계를 거친다.


모델 추론

LLM 추론에서 모델은 프롬프트를 받아서 이 인풋을 토큰화하고 벡터화한다(프리필링이라고도 함). 그리고 나서 사용자를 위한 출력을 생성하기 위해 모델을 통해 실행된다(디코딩 과정이라고도 함). LLM에서 개인 맞춤화 과정이 필요할 때, 이 과정은 더욱 흥미로워진다. 앞에서 언급했듯이 기업은 자체 벡터 데이터베이스에 데이터를 저장하고 LLM 커스터마이징 플랫폼을 사용해 LLM과 연결할 수 있다. 사용자가 자신의 앱에 프롬프트를 입력하면, LLM을 사용해 고유한 답변을 생성하기 위해 기업의 벡터 데이터베이스에서도 데이터가 추출된다. 비슷한 아키텍처를 사용하면 AI 에이전트가 기업이나 사용자의 환경 맥락을 파악하고 사용자를 대신해서 액션도 가능해진다. 데이터 보안, 모델 품질, 규정 준수를 보장하기 위해서는 이 과정 전반에 걸쳐 데이터를 추적하고 관리해야 한다. 그래서 데이터 서비스가 필요해진다. 

데이터 서비스

데이터 서비스는 데이터를 구성하고 보호하는 서비스를 총칭한다. AI 수요는 애플리케이션을 위한 데이터의 다양성과 규모, 그리고 데이터 관련 도구를 증가시키고 있다. 이는 데이터 관리, 보안, 그리고 데이터 관련 관행에 대한 거버넌스 보장에 있어 과제를 야기한다.
전통적인 데이터 보안은 데이터에 대한 접근을 보호하고 악의적인 행위자에 의해 접근되거나 도난당하지 않도록 하는 것을 포함한다. 오늘날 데이터의 양과 중요성을 고려할 때, 이러한 원칙은 여전히 유효하지만 훨씬 더 큰 규모로 적용된다. 데이터 보안 태세 관리, 데이터 접근 제어, 데이터 손실 방지, 데이터 탐지 및 대응과 같은 기능은 오늘날 데이터 보안 기업들의 중요한 카테고리다.
데이터 관측가능성은 데이터 파이프라인 전반에 걸친 데이터 품질과 성능의 모니터링이다. 이러한 도구들은 이상을 감지하고, 데이터 파이프라인에 대한 가시성(스키마 변경, 컴퓨팅 집약적 쿼리, 중요 객체)을 유지한다.

AI가 데이터 산업을 새롭게 재탄생시키다. 

AI가 완전히 새롭게 바꾼 데이터 산업의 면모를 하나씩 살펴보자. 

1. AI 에이전트와 애플리케이션을 위한 비정형 파이프라인 

AI 애플리케이션용 데이터 영역에서 일어난 가장 큰 변화는 비정형 데이터 파이프라인이 늘어난 것이다. 대화형 AI와 에이전트 개발에 회사가 가지고 있는 내부 데이터를 활용하고자 한다.
이런 파이프라인은 기존 데이터 파이프라인과 유사한 단계를 거친다. 추출, 변환, 인덱싱, 저장이 그것이다. 현재 가장 흔한 비정형 데이터는 대화형 AI 서비스를 구축하기 위해 필요한 PDF, 지식베이스, 이미지에서 추출한 텍스트다. 
포트폴리오사들을 살펴보면, 문서 유형에 맞는 자체 파서를 구축했다. 더 정확하고 신뢰할 만한 추출 방법을 계속 찾고 있고, 변환 단계에서 이 제품들은 기존 파이프라인과 갈라진다. 비정형 데이터 변환에는 청킹(데이터를 작은 단위로 분할), 메타데이터 추출(색인용), 각 청크의 임베딩(벡터 저장용)이 포함된다. 청킹 방법과 임베딩 모델은 검색 정확도에 큰 영향을 미친다. 그래서 포폴사들은 다양한 청킹 전략을 시도하고 있다.  코드나 법률 콘텐츠 같은 특정 도메인 데이터로 버티컬한 영역의 특화 임베딩 모델도 등장했다. 이 데이터는 벡터 호환 데이터베이스에 저장되고, 여러 도구들이 RAG와 에이전트를 통한 개인 맞춤형 LLM에 적용하기위한 쿼리 가능한 데이터 형식을 제공한다.

2. 검색 증강 생성(RAG)

검색 증강 생성(RAG)은 맞춤 데이터를 활용해 LLM 애플리케이션의 효율을 높이는 아키텍처 워크플로다. RAG에서는 데이터를 로드하고 쿼리할 수 있게 준비하거나 '인덱싱(색인화)'한다. 쿼리는 색인에 작용해 가장 관련성 높은 컨텍스트를 뽑아낸다. 이 컨텍스트와 쿼리는 프롬프트와 함께 LLM에 전달되고 LLM이 응답을 생성한다 이렇게 RAG는 데이터를 제품의 일부가 된다. 
RAG는 여러 이점이 있다. LLM에서 결과로 나오는 답은 사전 훈련된 지식과 데이터로 제한되기 때문에 검색 시점에서는 이미 오래된 정보가 되었거나 부정확한 응답으로 이어질 수 있다. RAG는 LLM에 외부 정보원가 접근해서 최신의 정보와 함께 정확한 답변을 제공할 수 있도록 도와준다. 사실 LLM 정확도에서 어려움을 겪는데, RAG는 LLM에 검증된 지식 베이스를 제공해 이 문제를 해결한다. RAG는 모델이 각주처럼 출처를 인용할 수 있게 해 최종 사용자의 신뢰를 구축한다.

3. 훈련과 추론 개선을 위한 데이터 큐레이션

최적의 훈련과 추론 성능을 위해 데이터 세트를 필터링하고 조직화하는 것을 데이터 큐레이션이라고 한다. 텍스트 분류, 유해 콘텐츠 필터, 중복 제거, 배치 크기 최적화, 성능기반 자원 최적화 등을 포함한다. 이 작업의 마지막 단계는 합성 데이터로 모델을 증강시킨다. 메타의 Llama-3 발표문 두 구절이 데이터 큐레이션의 중요성을 보여준다. 

훈련에 관해서: "최고의 언어 모델을 훈련하려면 대규모 고품질 훈련 데이터 세트 큐레이션이 핵심이다. Llama 3가 최고 품질의 데이터로 훈련되도록 일련의 데이터 필터링 파이프라인을 개발했다. 휴리스틱 필터, 유해 콘텐츠 필터, 의미기반 중복 제거, 데이터 품질 예측용 텍스트 분류기가 포함된다."
파인튜닝에 관해: "모델 품질의 가장 큰 개선은 세심한 데이터 큐레이션과 사람이 직접 주석을 작성한 다중 품질 보증에서 이루어졌다."

메타 AI 연구팀은 작년 데이터 큐레이션이 훈련 시간을 20%까지 단축하고 다운스트림 정확도를 개선할 수 있다는 논문을 발표했다. 더 중요한 것은 이 논문이 모델을 만드는 기업들이 훈련용 인터넷 데이터를 다 사용하고 난 후를 대비한 모델 개선 경로를 제시했다는 점이다. 모델을 훈련하고 파인튜닝하는 모든 기업은 자동화된 고품질 데이터 필터, 중복 제거, 분류기가 필요할 것이다. 이 논문의 저자 중 한 명인 아리 마르코스는 이런 비전을 추구하며 Datology AI를 설립했다.

4. AI를 위한 데이터 저장소

AI 데이터 저장소를 이끄는 세 가지 트렌드가 있다. 벡터 저장소, 데이터 레이크의 부상, 레이크하우스 투자다. 

벡터 데이터베이스는 임베딩이나 비정형 데이터를 포함한 데이터의 수치 표현을 저장하기때문에 AI 붐이 낳은 최대의 수혜자라 볼 수 있다. 벡터 데이터베이스의 배경은 이렇다. 수학적으로보면, 벡터는 크기와 방향을 모두 가져 공간의 값을 표현하기에 적합하다. AI에서 벡터는 데이터의 수치 표현이다. 이미지, 오디오, 비디오 같은 비정형 데이터를 의미 있는 숫자로 변환해 벡터 데이터베이스에 저장한다. 이 데이터에서 벡터 임베딩이 생성되어 "개"를 검색할 때 "늑대"나 "강아지"를 찾는 것과 같은 관련어의 의미론적 검색이 가능해진다.
벡터 데이터베이스는 크게 목적에 맞게 구축된 네이티브 벡터 데이터베이스와 벡터 지원이 추가된 기존 데이터베이스로 나눌 수 있다. LLM에서 개인 맞춤화가 가능해지기때문에 벡터 데이터베이스의 인기가 높아졌다. 기업들은 맞춤형 데이터를 벡터 데이터베이스의 임베딩으로 저장해서 개인 맞춤형으로 제공할 수 있다. 이 아키텍처를 활용해서 AI 에이전트도 만들 수 있다. 
AI 와 관련한 데이터 저장에서 또 다른 트렌드는 데이터 레이크하우스가 부상하고 있다는 점이다. 대부분의 기업이 데이터 레이크에 대량의 데이터를 저장하므로 맞춤형 AI는 그 데이터를 활용해야 한다. 데이터 레이크하우스는 데이터 레이크의 데이터를 관리하고 쿼리하는 아키텍처를 제공한다. 아이스버그, 델타 레이크, 후디 같은 오픈 테이블 형식으로 데이터를 조직화하는 것부터 시작한다. 데이터브릭스의 태뷸러 인수는 두 대형 오픈 테이블 형식(델타 레이크와 아이스버그)의 제작자를 통합하고 경쟁사의 진입을 막았다는 점에서 주요하게 볼 수 있다. 

5. AI 메모리

챗GPT가 AI 메모리를 출시한 이후 AI 메모리는 뜨거운 화제가 됐다. 일반적인 AI 시스템은 에피소드 기억(시간과 경험에 기반한 개인적인 기억)이 강하지 못하고, 개별 상호작용에서의 연속성이 부족하다. LLM은 본질적으로 기억상실증을 앓는 셈이다. 그래서 단기적이고 특정 상황에 치우쳐진 기억은 복잡한 순차적 추론과 다중 에이전트 시스템의 지식 공유를 저해한다.
다중 에이전트 시스템으로 AI의 방향이 바뀌면서, 서로 다른 에이전트 간의 메모리를 관리하고, 개인정보에 접근하고 통제하는 견고한 시스템이 필요해졌다. 각 에이전트의 기억은 세션(리퀘스트에 대해 결과가 나오기까지의 일련의 과정) 이 이루어지는 동시에, 세션을 걸쳐 저장하고 개인정보에 접근할 수 있어야한다. 에이전트들 간의 기억 공유와 같은 더 복잡한 메모리 메커니즘이 필요해지게 된다. 한 에이전트가 다른 에이전트들의 경험을 활용할 수 있어야 에이전트의 결정 능력이 향상되기 때문이다. 메모리 저장은 접근 빈도, 중요도, 비용을 기준으로 계층화되어야 할 것이다.

MemGPT는 현재 메모리 관리를 위한 주요 오픈소스 프레임워크고, 이들의 비전은 LLM이 OS의 그 다음 버전이 되는 것이다. OS에서 영감을 받은 MemGPT의 다층 메모리 아키텍처는 크게 두 가지로 메모리 유형을 구분한다. 

메인 컨텍스트: 메인 메모리/물리적 메모리/RAM에 상응
외부 컨텍스트: 디스크 메모리/디스크 저장소에 상응

메모리 혁신은 개인화, 학습, 성찰을 돕는다는 점에서 AI 애플리케이션 발전에 핵심이 될 것이다. 


생성형 AI의 부상으로 데이터 업계의 모든 부분이 변한 것은 아니지만, 많은 것이 바뀌고 있다. 정형 데이터 추출과 파이프라이닝, 검색 증강 생성(RAG), 데이터 큐레이션, 데이터 저장, AI 메모리 전반에 걸쳐 새로운 기술은 굉장히 흥미진진했다. 
펠리시스에서 우리는 AI와 관련된 데이터와 인프라 계층의 미래에 전념해왔다. 이것이 우리가 데이톨로지(데이터 큐레이션), 메타플레인(데이터 관측성), 마더덕(서버리스 데이터 웨어하우스)에 투자한 이유다. 실험 추적을 위한 웨이츠 & 바이어시스 같은 관련 도구들도 마찬가지다. AI 시장은 크고 계속 성장하고 있다. 챗봇에서 다중 에이전트 워크플로우까지, 우리는 이제 시작에 불과하다. 데이터 솔루션은 이러한 애플리케이션의 성공에 핵심이다. AI 워크로드를 지원하기 위해 거대한 데이터 비즈니스들이 구축될 것이다.

이 분야에서 무언가를 구축하고 있고 대화에 관심이 있다면 data@felicis.com으로 연락주시길!